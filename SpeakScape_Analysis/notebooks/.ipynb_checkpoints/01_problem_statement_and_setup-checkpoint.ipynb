{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035235c6-25ed-474f-998e-32affb0b1ac2",
   "metadata": {},
   "source": [
    "# Notebook 01 - Problem Statement And Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d5686-447c-48a9-ace2-27beb9cd755d",
   "metadata": {},
   "source": [
    "### SpeakScape — Presentation Feedback Powered by TED Talks\n",
    "\n",
    "**Group 4, l25dat4bi1f**\n",
    "CPH Business Academy Lyngby \n",
    "Exam Project 2025**\n",
    "\n",
    "### Collaborators  \n",
    "- Alberte Mary Wahlstrøm Vallentin — cph-av169@cphbusiness.dk  \n",
    "- Felicia Favrholdt — cph-ff62@cphbusiness.dk  \n",
    "- Fatima Majid Shamcizadh — cph-fs156@cphbusiness.dk\n",
    "\n",
    "### Project Title\n",
    "SpeakScape\n",
    "\n",
    "### Github Links \n",
    "- [Analysis 1](https://github.com/AlberteVallentin/SpeakScape)\n",
    "- [Analysis 2 & Streamlit App](https://github.com/FeliciaFavrholdt/Speakscape_BI_Exam_Group_4/tree/main)\n",
    "\n",
    "### Problem Statement\n",
    "How can SpeakScape provide actionable, data-driven feedback to users by analyzing their presentation text against TED Talk benchmarks to identify impactful linguistic patterns?\n",
    "\n",
    "### Research Questions\n",
    "1. What specific linguistic features—such as sentence complexity, pronoun usage, and rhetorical devices—are most predictive of audience engagement in TED Talks?\n",
    "2. How can we effectively correlate these features with engagement metrics like view count?\n",
    "3. How can we use these insights to offer personalized feedback on user-submitted texts?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be8bec-8e6d-40c2-988e-b2eef5b14ddc",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "Effective public speaking plays a critical role in personal and professional success. However, most individuals lack access to high-quality, personalized feedback on their communication style.\n",
    "\n",
    "By leveraging text analytics and AI, SpeakScape aims to bridge this gap by learning from expertly crafted TED Talks and helping users enhance their own presentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49271a31-f6b5-40f4-9434-384318480766",
   "metadata": {},
   "source": [
    "### Project Goals\n",
    "\n",
    "- Identify linguistic patterns that correlate with high user engagement.\n",
    "- Train a classifier to distinguish TED-style speech from user submissions.\n",
    "- Generate actionable feedback to improve user presentations.\n",
    "\n",
    "### Hypotheses\n",
    "\n",
    "- Linguistic richness, clarity, and emotional appeal are more prevalent in TED Talks.\n",
    "- Machine learning can detect these patterns and predict presentation quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2718efe-1984-4c22-b369-c5c14817c36b",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c505a0-ab8f-4e75-bcb4-2ec73e55be82",
   "metadata": {},
   "source": [
    "## Project Scope and Impact\n",
    "\n",
    "SpeakScape is a machine learning–driven system designed to analyze TED Talk transcripts in order to understand the linguistic elements that contribute to effective public speaking. By leveraging natural language processing (NLP) and engagement metrics, the project aims to provide meaningful, personalized feedback on presentation content.\n",
    "\n",
    "### Key Objectives\n",
    "\n",
    "- Detect high-impact linguistic patterns common to successful TED Talks\n",
    "- Benchmark user-generated transcripts against TED standards\n",
    "- Deliver actionable feedback to enhance the clarity, structure, and impact of user speeches\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Outcomes\n",
    "\n",
    "The project will deliver the following components:\n",
    "\n",
    "- A cleaned, unified dataset merging TED_2017 and TED_2020, annotated for analysis\n",
    "- A trained machine learning model capable of predicting TED-likeness or engagement potential\n",
    "- A fully functional Streamlit application that allows users to upload presentations and receive detailed linguistic feedback\n",
    "- Well-documented, reproducible code and workflows across modular Jupyter notebooks\n",
    "\n",
    "---\n",
    "\n",
    "## Impact and Beneficiaries\n",
    "\n",
    "SpeakScape provides value across multiple user groups:\n",
    "\n",
    "- **Students and professionals** who need to prepare for presentations, pitches, or interviews\n",
    "- **Educators** who teach communication skills and seek scalable tools for assessment and feedback\n",
    "- **AI and NLP researchers** interested in transparent, explainable models of language effectiveness\n",
    "\n",
    "By aligning speech content with proven TED Talk benchmarks, SpeakScape empowers users to improve their public speaking through structured, data-backed feedback—encouraging more engaging and effective communication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094089a-b4a8-4582-900a-17db9320495e",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfa1aa1-bbe1-496b-a50e-5511e7ec1027",
   "metadata": {},
   "source": [
    "## Brief Annotation\n",
    "\n",
    "**1. Which challenge would you like to address?**\n",
    "\n",
    "We aim to address the challenge of providing personalized, data-driven feedback to public speakers—particularly students and professionals—by analyzing how their presentation content compares to highly engaging TED Talks. The core challenge is helping users understand what makes a talk effective from a linguistic and structural perspective.\n",
    "\n",
    "**2. Why is this challenge an important or interesting research goal?**\n",
    "    \n",
    "Strong communication is a critical skill in education, business, and public speaking, yet it's rarely evaluated with objective, content-based tools. This research is interesting because it bridges natural language processing (NLP) and audience engagement analytics to make expert-level feedback scalable and automated. By using TED Talks as a benchmark, we explore the linguistic patterns that correlate with high impact.\n",
    "\n",
    "**3. What is the expected solution your project would provide?**\n",
    "    \n",
    "Our solution will produce a machine learning model trained on TED data to detect linguistic traits that align with high engagement. Combined with a Streamlit app, the system allows users to upload their own presentation text and receive feedback on clarity, complexity, rhetorical style, and TED-likeness. The model highlights how closely their content aligns with successful talks and where they can improve.\n",
    "\n",
    "**4. What would be the positive impact of the solution, and which category of users could benefit from it?**\n",
    "\n",
    "The solution empowers non-expert speakers—including students, educators, startup founders, and professionals—to refine their content using empirical, explainable language metrics. It supports inclusive, scalable skill development in a way that's usually only available through costly 1-on-1 coaching. Ultimately, it democratizes access to communication feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c7666-4b77-4ee2-899e-c5fff97b628b",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d2371-a5d8-4574-aa6b-c5aaf2bd2b75",
   "metadata": {},
   "source": [
    "## Notebooks\n",
    "\n",
    "The project is implemented through six modular notebooks:\n",
    "\n",
    "- **01_Problem_Statement_and_Setup**  \n",
    "   Define the research goals, problem formulation, and prepare the working environment.\n",
    "\n",
    "- **02_Dataset_Cleaning_Overview**  \n",
    "   Merge TED datasets, clean raw fields, drop irrelevant columns, and document preprocessing logic.\n",
    "\n",
    "- **03_Data_Loading_and_Preprocessing**  \n",
    "   Normalize transcripts, extract linguistic features (e.g., word count, readability), and save a ready-to-model dataset.\n",
    "\n",
    "- **04_Exploratory_Data_Analysis (EDA)**  \n",
    "   Visualize linguistic patterns and engagement metrics to guide feature engineering.\n",
    "\n",
    "- **05_Model_Training_and_Evaluation**  \n",
    "   Train classification models to detect TED-like linguistic features and predict engagement.\n",
    "\n",
    "- **06_Results_and_Interpretation**  \n",
    "   Interpret model outputs, extract feature importance, and design content feedback strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918615f-dcd1-4ae5-ab35-3f139ec1a6bd",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db442c9a-1f18-41b9-b113-84c51b2a7082",
   "metadata": {},
   "source": [
    "### Streamlit Application\n",
    "\n",
    "A separate **Streamlit web application** is used to deliver feedback interactively, allowing users to compare their transcripts against TED benchmarks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202030f-6470-45a9-baa3-b07c9ff7f06e",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e79327-a2f0-43c7-ba4c-e97bcd282309",
   "metadata": {},
   "source": [
    "## Execution Plan: BI Sprints\n",
    "\n",
    "**Sprint 1: Problem Formulation**  \n",
    "Notebook: `01_problem_statement_and_setup.ipynb`  \n",
    "Focus: Define problem, goals, research questions, and project structure.  \n",
    "\n",
    "**Sprint 2: Data Collection & Cleaning**  \n",
    "Notebook: `02_data_loading_and_preprocessing.ipynb`  \n",
    "Focus: Load and clean TED datasets, recover transcripts, merge into a consistent schema.  \n",
    "\n",
    "**Sprint 3: Feature Engineering and Machine Learning**  \n",
    "Notebooks: `04_feature_engineering.ipynb`, `05_model_training.ipynb`  \n",
    "Focus: Extract features from transcripts, train classifiers to predict TED-likeness, and analyze important linguistic features.  \n",
    "\n",
    "**Sprint 4: Business Application**  \n",
    "Assets: `streamlit_app.py`, `06_results_and_interpretation.ipynb`  \n",
    "Focus: Deploy a user-facing Streamlit application that provides actionable presentation feedback. Include visual interpretation and documentation of results.\n",
    "\n",
    "This project follows a structured BI development lifecycle, using notebooks for reproducible analysis and Streamlit for interactive delivery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a1097-99f2-4379-b41d-e502ab3c47e7",
   "metadata": {},
   "source": [
    "#### Timeline & Milestones\n",
    " \n",
    "| Milestone                                | Deliverables                                      |\n",
    "|-------------------------------------------|---------------------------------------------------|\n",
    " Define problem & gather data              | Project scope, TED_2017 + TED_2020 datasets       |\n",
    " Dataset cleaning & unification            | `cleaned_data.csv`, Notebook 02                   |\n",
    " Preprocessing & feature extraction        | `preprocessed_data.csv`, Notebook 03              |\n",
    " Exploratory Data Analysis (EDA)           | Plots & correlation insights, Notebook 04         |\n",
    " Feature engineering + model training      | Model pipeline, Notebook 05                       |\n",
    " Results interpretation + Streamlit UI     | Final models, Notebook 06 + Streamlit app         |\n",
    " Team review, documentation, hand-in       | GitHub updated, final `.md` summary + PDF export  |\n",
    "\n",
    "\n",
    "#### Team Member Engagement\n",
    "\n",
    "| Member    | Tasks                                         |\n",
    "|-----------|------------------------------------------------------|\n",
    "| Alberte   |       |\n",
    "| Felicia   | |\n",
    "| Fatima    | |\n",
    "\n",
    "All members are involved in review and testing before deliverables are pushed to GitHub or submitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516356a-ad25-4444-8620-d3575b07d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Project Directory Structure\n",
    "\n",
    "The project is organized using a modulyar and reproducible data science workflow:\n",
    "\n",
    "SpeakScape_Analysis/\n",
    "│\n",
    "├── data/                  \n",
    "│   ├── combined_dataset.csv         # Merged TED 2017 + 2020 data\n",
    "│   ├── cleaned_data.csv             # Output from cleaning pipeline\n",
    "│   └── preprocessed_data.csv        # Feature-rich version for modeling\n",
    "│\n",
    "├── models/               \n",
    "│   └── *.pkl / *.joblib             # Trained ML models\n",
    "│\n",
    "├── notebooks/           \n",
    "│   ├── 01_problem_statement_and_setup.ipynb\n",
    "│   ├── 02_dataset_cleaning_overview.ipynb\n",
    "│   ├── 03_data_loading_and_preprocessing.ipynb\n",
    "│   ├── 04_exploratory_data_analysis.ipynb\n",
    "│   ├── 05_model_training_and_evaluation.ipynb\n",
    "│   └── 06_results_and_interpretation.ipynb\n",
    "│\n",
    "├── plots/                 \n",
    "│   └── *.png                         # All visualizations generated in EDA and preprocessing\n",
    "│\n",
    "├── reports/               \n",
    "│   ├── *.json                       # Notebook summaries\n",
    "│   └── Exam_Group4_SpeakScape_Summary.md\n",
    "│\n",
    "├── streamlit_app/       \n",
    "│   ├── app.py                       # Main app file\n",
    "│   └── utils.py / model_loaders.py  # App logic and prediction helpers\n",
    "│\n",
    "├── utils/\n",
    "│   └── setup.py / save_tools.py     # Reusable functions for all notebooks\n",
    "│\n",
    "├── .gitignore\n",
    "├── requirements.txt\n",
    "└── README.md\n",
    "\n",
    "### Workflow Procedures\n",
    "\n",
    "- Notebooks save processed files (`.csv`) and `.json` summaries to ensure reproducibility.\n",
    "- `IPython.notebook.save_checkpoint()` ensures notebook state is saved on run.\n",
    "- Preprocessed data is versioned (e.g., `cleaned_data_v1.csv`).\n",
    "- ML models are saved using `joblib` for app integration.\n",
    "- Final review and packaging handled before exam hand-in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185645f9-7188-49ad-9360-6fb9420c21d6",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f36215-b67e-4ae7-bd28-8dd51a0f9a43",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e2e40-8ad3-45f9-87f6-511f30997184",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "We use standard Python libraries for data analysis, natural language processing, and machine learning. All paths are defined as relative to ensure reproducibility across machines and platforms.\n",
    "\n",
    "### Libraries Used\n",
    "\n",
    "- **Pandas** — Data manipulation and DataFrame operations  \n",
    "- **NumPy** — Numerical computations  \n",
    "- **Matplotlib & Seaborn** — Data visualization  \n",
    "- **NLTK** — Tokenization, lemmatization, stopword removal  \n",
    "- **Scikit-learn** — Modeling, metrics, and preprocessing tools  \n",
    "- **Joblib** — Model persistence  \n",
    "- **Streamlit** — Interactive web application for feedback delivery\n",
    "\n",
    "### Setup Procedures\n",
    "\n",
    "1. Create a virtual environment using Anaconda or `venv`\n",
    "2. Install dependencies:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24620d42-9f8e-4521-964a-9f8b0425abaf",
   "metadata": {},
   "source": [
    "#### Development Tools\n",
    "\n",
    "- **IDE:** Visual Studio Code (VS Code) with Jupyter support\n",
    "- **Version Control:** Git (GitHub remote)\n",
    "- **Package Management:** Anaconda / pip (via `requirements.txt`)\n",
    "- **Notebook Environment:** Jupyter Notebooks, Streamlit for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f967a-a01d-4a16-a38b-3f29141aff35",
   "metadata": {},
   "source": [
    "\n",
    "### Platform Requirements\n",
    "\n",
    "- **Python** 3.9 or higher  \n",
    "- **Jupyter Notebook** (or Visual Studio Code with Jupyter extension)  \n",
    "- **Streamlit** version 1.20 or later  \n",
    "\n",
    "All notebooks are executed from within the `notebooks/` directory. Output files such as datasets, visualizations, and model summaries are saved to corresponding subdirectories located one level up for consistency across the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1415ff23-f849-4cfb-8ba5-41f809cdf85e",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61bcefc-edf4-4af2-8f17-9de11a4e2c2f",
   "metadata": {},
   "source": [
    "### Project initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5055505-6730-4476-adf1-3b3f3917d077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment initialized.\n"
     ]
    }
   ],
   "source": [
    "from utils.setup import init_environment\n",
    "init_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86284842-7100-43ef-99c3-6a70605a20d6",
   "metadata": {},
   "source": [
    "### Initialization Function\n",
    "\n",
    "The `init_environment()` function performs the following setup tasks:\n",
    "\n",
    "- Applies consistent Seaborn and Matplotlib visual styles\n",
    "- Verifies the existence of required directories: `../data`, `../plots`, `../models`, and `../reports`\n",
    "- Ensures a clean, reproducible environment for all notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0ceff-cc18-406e-aab2-713f42694622",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e959fd3-b7d3-41bc-a5c5-b42a9b33b1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply Seaborn styling (this sets both matplotlib and seaborn visuals)\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"deep\")\n",
    "\n",
    "\n",
    "# Create directories for reproducibility\n",
    "folders = [\"../data\", \"../models\", \"../plots\", \"../reports\"]\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "print(\"Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37b3341d-2031-48dc-9ec2-cf07db1130c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook save triggered.\n",
      "Summary saved to: ../reports/01_problem_statement_and_setup_summary_2025-05-26_03-38-27.json\n"
     ]
    }
   ],
   "source": [
    "from utils.save_tools import save_notebook_and_summary\n",
    "\n",
    "save_notebook_and_summary(\n",
    "    notebook_name=\"01_problem_statement_and_setup\",\n",
    "    summary={\n",
    "        \"description\": \"Established the project scope and objectives for SpeakScape, outlined key research questions, defined the BI sprint structure, and initialized the working environment.\",\n",
    "        \"team_members\": [\n",
    "            \"Alberte Mary Wahlstrøm Vallentin\",\n",
    "            \"Felicia Favrholdt\",\n",
    "            \"Fatima Majid Shamcizadh\"\n",
    "        ],\n",
    "        \"sprints_defined\": 4,\n",
    "        \"notebooks_planned\": [\n",
    "            \"01_problem_statement_and_setup\",\n",
    "            \"02_dataset_cleaning_overview\",\n",
    "            \"03_data_loading_and_preprocessing\",\n",
    "            \"04_exploratory_data_analysis\",\n",
    "            \"05_model_training_and_evaluation\",\n",
    "            \"06_results_and_interpretation\"\n",
    "        ],\n",
    "        \"folders_created\": [\"data\", \"models\", \"plots\", \"reports\"],\n",
    "        \"tools_used\": [\n",
    "            \"Python 3.9\", \"Jupyter Notebook\", \"VS Code\", \"GitHub\", \"Streamlit\"\n",
    "        ]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39c3bc-ff08-4b29-bbc5-880591ad63f6",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
